{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db6f6f8d-3393-4d38-ba6e-285584830e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "model = KeyedVectors.load_word2vec_format('50thousand.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6846073-8175-4031-996f-a05812bd840d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'FRAM' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_397104/154936274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FRAM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxxenv/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m         all_keys = [\n\u001b[1;32m    844\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cxxenv/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'FRAM' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "for key, value in model.most_similar('FRAM', topn=100000):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52126d3c-62c5-486e-8f61-50c7e8f25d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需的库\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 定义需要计算相似性的词汇\n",
    "material = ['BaTiO3','PZT','PVDF','LiNbO3','BiFeO3']\n",
    "application = ['sensors','actuators','filters','capacitors']\n",
    "mechanism = ['polarization','strain','capacitive']\n",
    "structure = ['nanostructure','layered','composite']\n",
    "property = ['piezoelectricity']\n",
    "characterization = ['SEM','TEM','XRD','AFM','IR']\n",
    "preparation = ['CVD','PLD','PVD','MBE']\n",
    "target_words = ['material','application','mechanism','structure','property'\n",
    "               ,'characterization','preparation']\n",
    "\n",
    "# 计算余弦相似性\n",
    "similarities = {}\n",
    "\n",
    "# 计算各类别词汇与目标词汇的相似性\n",
    "categories = {'material':material,'application':application,'mechanism':mechanism,\n",
    "              'structure':structure,'property':property,\n",
    "              'characterization':characterization,'preparation':preparation}\n",
    "\n",
    "for target_word, category in categories.items():\n",
    "    if target_word in target_words:\n",
    "        for word in category:\n",
    "            if word in model and target_word in model:\n",
    "                similarities[(word, target_word)] = model.similarity(word, target_word)\n",
    "\n",
    "# 计算target_words之间的相似性\n",
    "for i in range(len(target_words)):\n",
    "    for j in range(i + 1, len(target_words)):\n",
    "        word1 = target_words[i]\n",
    "        word2 = target_words[j]\n",
    "        if word1 in model and word2 in model:\n",
    "            similarities[(word1, word2)] = model.similarity(word1, word2)\n",
    "\n",
    "# 创建图\n",
    "G = nx.Graph()\n",
    "\n",
    "# 添加节点\n",
    "all_words = material + application + mechanism + structure + property + characterization + preparation + target_words\n",
    "for word in all_words:\n",
    "    G.add_node(word)\n",
    "\n",
    "# 添加边并设置宽度\n",
    "edges = []\n",
    "for (word1, word2), sim in similarities.items():\n",
    "    G.add_edge(word1, word2, weight=sim * 10)  # 乘以10使边的宽度更明显\n",
    "    edges.append((word1, word2))\n",
    "\n",
    "# 绘制图\n",
    "plt.figure(figsize=(18, 18), dpi=1000)\n",
    "pos = nx.spring_layout(G, seed=42, k=0.5)  # 增加k值以增大节点间距\n",
    "\n",
    "# 根据权重绘制边\n",
    "weights = [G[u][v]['weight'] for u, v in edges]\n",
    "\n",
    "# 绘制边，设置边颜色和透明度\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=[weight * 2 for weight in weights], edge_color='bisque', alpha=0.6)  # 乘以2增加宽度\n",
    "\n",
    "# 绘制特定节点为黄色\n",
    "yellow_nodes = target_words\n",
    "other_nodes = set(G.nodes) - set(yellow_nodes)\n",
    "\n",
    "# 绘制节点和标签\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=yellow_nodes, node_size=3000, node_color='skyblue')  # 设置节点颜色为黄色\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=other_nodes, node_size=3000, node_color='lightgray')  # 设置其他节点颜色\n",
    "nx.draw_networkx_labels(G, pos, font_size=12)\n",
    "\n",
    "plt.title('Knowledge Graph Based on Cosine Similarity')\n",
    "plt.axis('off')  # 关闭坐标轴\n",
    "\n",
    "plt.savefig('ferroelectricity-knowledge-graph.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895fad3b-9030-4de9-b868-d33bc2fe0c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3834a6a-dc8f-4853-8235-eb2c934c3244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec131c1-9703-419c-bcba-a3ce702805c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
